{
 "cells": [
  {
   "cell_type": "code",
   "id": "37fac817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:47:46.409291319Z",
     "start_time": "2025-11-19T01:47:46.392561462Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tarfile\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.edgecolor\": \"0.3\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"font.size\": 12,\n",
    "        \"axes.titlesize\": 14,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"axes.titleweight\": \"bold\",\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"legend.frameon\": False,\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "e36a4b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:47:46.419855660Z",
     "start_time": "2025-11-19T01:47:46.410536439Z"
    }
   },
   "source": [
    "# unzip yahoo raw tgz file\n",
    "raw_file_path = \"../../datasets/Yahoo/raw/dataset.tgz\"\n",
    "extract_path = \"../../datasets/Yahoo/\"\n",
    "unzip_dir = \"../../datasets/Yahoo/data\"\n",
    "\n",
    "if not os.path.exists(unzip_dir):\n",
    "    os.makedirs(unzip_dir)\n",
    "    with tarfile.open(raw_file_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "    logging.info(f\"Extracted {raw_file_path} to {extract_path}\")\n",
    "    os.rename(\n",
    "        \"../../datasets/Yahoo/ydata-labeled-time-series-anomalies-v1_0\",\n",
    "        \"../../datasets/Yahoo/data\",\n",
    "    )\n",
    "else:\n",
    "    logging.info(f\"Directory {unzip_dir} already exists. Skipping extraction.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Directory ../../datasets/Yahoo/data already exists. Skipping extraction.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "c0345686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:47:46.473106268Z",
     "start_time": "2025-11-19T01:47:46.420977028Z"
    }
   },
   "source": [
    "# Yahoo A1Benchmark\n",
    "data_dir = \"../../datasets/Yahoo/data/A1Benchmark\"\n",
    "\n",
    "# rename all real_XX.csv to XX.csv\n",
    "# for file in os.listdir(data_dir):\n",
    "#     if file.startswith(\"real_\") and file.endswith(\".csv\"):\n",
    "#         df = pl.read_csv(os.path.join(data_dir, file))\n",
    "#         df.rename({\"is_anomaly\": \"label\"}).write_csv(\n",
    "#             os.path.join(data_dir, file.replace(\"real_\", \"\"))\n",
    "#         )\n",
    "#         os.remove(os.path.join(data_dir, file))\n",
    "#         logging.info(f\"Processed {file}.\")\n",
    "\n",
    "# Read a sample file\n",
    "sample_file = os.path.join(data_dir, \"1.csv\")\n",
    "sample = pl.read_csv(\n",
    "    sample_file,\n",
    "    schema={\"timestamp\": pl.UInt64, \"value\": pl.Float64, \"label\": pl.Int8},\n",
    ")\n",
    "print(f\"Sample file: 1.csv\")\n",
    "print(f\"Shape: {sample.shape}\")\n",
    "print(f\"Columns: {sample.columns}\")\n",
    "sample.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file: 1.csv\n",
      "Shape: (1420, 3)\n",
      "Columns: ['timestamp', 'value', 'label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────────┬──────────┬───────┐\n",
       "│ timestamp ┆ value    ┆ label │\n",
       "│ ---       ┆ ---      ┆ ---   │\n",
       "│ u64       ┆ f64      ┆ i8    │\n",
       "╞═══════════╪══════════╪═══════╡\n",
       "│ 1         ┆ 0.0      ┆ 0     │\n",
       "│ 2         ┆ 0.091758 ┆ 0     │\n",
       "│ 3         ┆ 0.172297 ┆ 0     │\n",
       "│ 4         ┆ 0.226219 ┆ 0     │\n",
       "│ 5         ┆ 0.176358 ┆ 0     │\n",
       "└───────────┴──────────┴───────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>value</th><th>label</th></tr><tr><td>u64</td><td>f64</td><td>i8</td></tr></thead><tbody><tr><td>1</td><td>0.0</td><td>0</td></tr><tr><td>2</td><td>0.091758</td><td>0</td></tr><tr><td>3</td><td>0.172297</td><td>0</td></tr><tr><td>4</td><td>0.226219</td><td>0</td></tr><tr><td>5</td><td>0.176358</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "39b54375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:47:46.491589619Z",
     "start_time": "2025-11-19T01:47:46.475704059Z"
    }
   },
   "source": [
    "# plotting function\n",
    "def plot_yahoo_timeseries(\n",
    "    df: pl.DataFrame, split_at: float = 0.5, figsize=(14, 6), title=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single Yahoo time series, marking anomalies and distinguishing train/test sets\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing 'timestamp', 'value', and 'label' columns\n",
    "        split_at: fraction to split train/test sets (default: 0.5)\n",
    "        figsize: figure size (default: (14, 6))\n",
    "        title: custom title for the plot (optional)\n",
    "\n",
    "    Returns:\n",
    "        fig: matplotlib figure object\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "    # Extract data\n",
    "    timestamps = df[\"timestamp\"]\n",
    "    values = df[\"value\"]\n",
    "    labels = df[\"label\"]\n",
    "\n",
    "    length = len(df)\n",
    "    train_cutoff = timestamps[int(length * split_at) - 1]\n",
    "\n",
    "    # Split train and test sets\n",
    "    train_mask = timestamps <= train_cutoff\n",
    "    test_mask = timestamps > train_cutoff\n",
    "\n",
    "    # Train set\n",
    "    train_timestamps = timestamps.filter(train_mask)\n",
    "    train_values = values.filter(train_mask)\n",
    "    train_labels = labels.filter(train_mask)\n",
    "\n",
    "    # Test set\n",
    "    test_timestamps = timestamps.filter(test_mask)\n",
    "    test_values = values.filter(test_mask)\n",
    "    test_labels = labels.filter(test_mask)\n",
    "\n",
    "    # Plot train set (blue)\n",
    "    if len(train_timestamps) > 0:\n",
    "        ax.plot(\n",
    "            train_timestamps,\n",
    "            train_values,\n",
    "            color=\"#2E86AB\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8,\n",
    "            label=\"Train\",\n",
    "        )\n",
    "        # Train set anomalies\n",
    "        train_anomaly_mask = train_labels == 1\n",
    "        if train_anomaly_mask.sum() > 0:\n",
    "            ax.scatter(\n",
    "                train_timestamps.filter(train_anomaly_mask),\n",
    "                train_values.filter(train_anomaly_mask),\n",
    "                color=\"#E63946\",\n",
    "                s=40,\n",
    "                marker=\"o\",\n",
    "                zorder=5,\n",
    "                edgecolors=\"darkred\",\n",
    "                linewidths=1.2,\n",
    "            )\n",
    "\n",
    "    # Plot test set (green)\n",
    "    if len(test_timestamps) > 0:\n",
    "        ax.plot(\n",
    "            test_timestamps,\n",
    "            test_values,\n",
    "            color=\"#06A77D\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8,\n",
    "            label=\"Test\",\n",
    "        )\n",
    "        # Test set anomalies\n",
    "        test_anomaly_mask = test_labels == 1\n",
    "        if test_anomaly_mask.sum() > 0:\n",
    "            ax.scatter(\n",
    "                test_timestamps.filter(test_anomaly_mask),\n",
    "                test_values.filter(test_anomaly_mask),\n",
    "                color=\"#E63946\",\n",
    "                s=40,\n",
    "                marker=\"o\",\n",
    "                zorder=5,\n",
    "                edgecolors=\"darkred\",\n",
    "                linewidths=1.2,\n",
    "                label=\"Anomaly\",\n",
    "            )\n",
    "\n",
    "    # Add vertical line marking train/test split\n",
    "    ax.axvline(x=train_cutoff, color=\"gray\", linestyle=\"--\", linewidth=2, alpha=0.5)\n",
    "\n",
    "    # Statistics\n",
    "    total_anomalies = (labels == 1).sum()\n",
    "    train_anomalies = (train_labels == 1).sum()\n",
    "    test_anomalies = (test_labels == 1).sum()\n",
    "\n",
    "    # Set title\n",
    "    if title is None:\n",
    "        title = (\n",
    "            f\"Total: {len(values)} pts | \"\n",
    "            f\"Train: {len(train_values)} pts ({train_anomalies} anomalies) | \"\n",
    "            f\"Test: {len(test_values)} pts ({test_anomalies} anomalies)\"\n",
    "        )\n",
    "\n",
    "    ax.set_title(\n",
    "        title,\n",
    "        fontsize=13,\n",
    "        fontweight=\"bold\",\n",
    "        pad=10,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Timestamp (hours)\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Value\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    # Beautify plot\n",
    "    ax.grid(True, alpha=0.3, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0, 1),\n",
    "        fontsize=10,\n",
    "        framealpha=0.95,\n",
    "        edgecolor=\"gray\",\n",
    "        fancybox=True,\n",
    "    )\n",
    "\n",
    "    # Remove top and right spines\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "d052da75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:48:08.884179962Z",
     "start_time": "2025-11-19T01:47:46.519844320Z"
    }
   },
   "source": [
    "# remove 7 from all ids\n",
    "ids = list(range(1, 68))\n",
    "ids.remove(7)\n",
    "if os.path.exists(os.path.join(data_dir, \"7.csv\")):\n",
    "    os.remove(os.path.join(data_dir, \"7.csv\"))\n",
    "    logging.info(\"Removed file 7.csv due to known data issues.\")\n",
    "os.makedirs(\"../../figures/datasets/YaHoo\", exist_ok=True)\n",
    "for id in ids:\n",
    "    file_path = os.path.join(data_dir, f\"{id}.csv\")\n",
    "    df = pl.read_csv(\n",
    "        file_path,\n",
    "        schema={\"timestamp\": pl.UInt64, \"value\": pl.Float64, \"label\": pl.Int8},\n",
    "    )\n",
    "\n",
    "    fig = plot_yahoo_timeseries(\n",
    "        df,\n",
    "        figsize=(14, 6),\n",
    "        title=f\"Yahoo Time Series - {id}\",\n",
    "    )\n",
    "    fig.savefig(\n",
    "        f\"../../figures/datasets/YaHoo/A1-{id}.png\", dpi=150, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    logging.info(f\"Saved plot for File {id} as A1-{id}.png\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved plot for File 1 as A1-1.png\n",
      "INFO:root:Saved plot for File 2 as A1-2.png\n",
      "INFO:root:Saved plot for File 3 as A1-3.png\n",
      "INFO:root:Saved plot for File 4 as A1-4.png\n",
      "INFO:root:Saved plot for File 5 as A1-5.png\n",
      "INFO:root:Saved plot for File 6 as A1-6.png\n",
      "INFO:root:Saved plot for File 8 as A1-8.png\n",
      "INFO:root:Saved plot for File 9 as A1-9.png\n",
      "INFO:root:Saved plot for File 10 as A1-10.png\n",
      "INFO:root:Saved plot for File 11 as A1-11.png\n",
      "INFO:root:Saved plot for File 12 as A1-12.png\n",
      "INFO:root:Saved plot for File 13 as A1-13.png\n",
      "INFO:root:Saved plot for File 14 as A1-14.png\n",
      "INFO:root:Saved plot for File 15 as A1-15.png\n",
      "INFO:root:Saved plot for File 16 as A1-16.png\n",
      "INFO:root:Saved plot for File 17 as A1-17.png\n",
      "INFO:root:Saved plot for File 18 as A1-18.png\n",
      "INFO:root:Saved plot for File 19 as A1-19.png\n",
      "INFO:root:Saved plot for File 20 as A1-20.png\n",
      "INFO:root:Saved plot for File 21 as A1-21.png\n",
      "INFO:root:Saved plot for File 22 as A1-22.png\n",
      "INFO:root:Saved plot for File 23 as A1-23.png\n",
      "INFO:root:Saved plot for File 24 as A1-24.png\n",
      "INFO:root:Saved plot for File 25 as A1-25.png\n",
      "INFO:root:Saved plot for File 26 as A1-26.png\n",
      "INFO:root:Saved plot for File 27 as A1-27.png\n",
      "INFO:root:Saved plot for File 28 as A1-28.png\n",
      "INFO:root:Saved plot for File 29 as A1-29.png\n",
      "INFO:root:Saved plot for File 30 as A1-30.png\n",
      "INFO:root:Saved plot for File 31 as A1-31.png\n",
      "INFO:root:Saved plot for File 32 as A1-32.png\n",
      "INFO:root:Saved plot for File 33 as A1-33.png\n",
      "INFO:root:Saved plot for File 34 as A1-34.png\n",
      "INFO:root:Saved plot for File 35 as A1-35.png\n",
      "INFO:root:Saved plot for File 36 as A1-36.png\n",
      "INFO:root:Saved plot for File 37 as A1-37.png\n",
      "INFO:root:Saved plot for File 38 as A1-38.png\n",
      "INFO:root:Saved plot for File 39 as A1-39.png\n",
      "INFO:root:Saved plot for File 40 as A1-40.png\n",
      "INFO:root:Saved plot for File 41 as A1-41.png\n",
      "INFO:root:Saved plot for File 42 as A1-42.png\n",
      "INFO:root:Saved plot for File 43 as A1-43.png\n",
      "INFO:root:Saved plot for File 44 as A1-44.png\n",
      "INFO:root:Saved plot for File 45 as A1-45.png\n",
      "INFO:root:Saved plot for File 46 as A1-46.png\n",
      "INFO:root:Saved plot for File 47 as A1-47.png\n",
      "INFO:root:Saved plot for File 48 as A1-48.png\n",
      "INFO:root:Saved plot for File 49 as A1-49.png\n",
      "INFO:root:Saved plot for File 50 as A1-50.png\n",
      "INFO:root:Saved plot for File 51 as A1-51.png\n",
      "INFO:root:Saved plot for File 52 as A1-52.png\n",
      "INFO:root:Saved plot for File 53 as A1-53.png\n",
      "INFO:root:Saved plot for File 54 as A1-54.png\n",
      "INFO:root:Saved plot for File 55 as A1-55.png\n",
      "INFO:root:Saved plot for File 56 as A1-56.png\n",
      "INFO:root:Saved plot for File 57 as A1-57.png\n",
      "INFO:root:Saved plot for File 58 as A1-58.png\n",
      "INFO:root:Saved plot for File 59 as A1-59.png\n",
      "INFO:root:Saved plot for File 60 as A1-60.png\n",
      "INFO:root:Saved plot for File 61 as A1-61.png\n",
      "INFO:root:Saved plot for File 62 as A1-62.png\n",
      "INFO:root:Saved plot for File 63 as A1-63.png\n",
      "INFO:root:Saved plot for File 64 as A1-64.png\n",
      "INFO:root:Saved plot for File 65 as A1-65.png\n",
      "INFO:root:Saved plot for File 66 as A1-66.png\n",
      "INFO:root:Saved plot for File 67 as A1-67.png\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "4f6d5433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:48:09.185618897Z",
     "start_time": "2025-11-19T01:48:08.924162993Z"
    }
   },
   "source": [
    "train_dir = \"../../datasets/Yahoo/train/A1\"\n",
    "test_dir = \"../../datasets/Yahoo/test/A1\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "split_at = 0.5\n",
    "\n",
    "for id in ids:\n",
    "    file_path = os.path.join(data_dir, f\"{id}.csv\")\n",
    "    df = pl.read_csv(\n",
    "        file_path,\n",
    "        schema={\"timestamp\": pl.UInt64, \"value\": pl.Float64, \"label\": pl.Int8},\n",
    "    )\n",
    "\n",
    "    cutoff = df[\"timestamp\"][int(len(df) * split_at) - 1]\n",
    "    train_df = df.filter(pl.col(\"timestamp\") <= cutoff)\n",
    "    test_df = df.filter(pl.col(\"timestamp\") > cutoff)\n",
    "\n",
    "    train_df.write_csv(os.path.join(train_dir, f\"{id}.csv\"))\n",
    "    test_df.write_csv(os.path.join(test_dir, f\"{id}.csv\"))\n",
    "\n",
    "    print(\n",
    "        f\"Saved File {id}: Train ({train_df.shape[0]} pts), Test ({test_df.shape[0]} pts)\"\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved File 1: Train (710 pts), Test (710 pts)\n",
      "Saved File 2: Train (719 pts), Test (720 pts)\n",
      "Saved File 3: Train (730 pts), Test (731 pts)\n",
      "Saved File 4: Train (711 pts), Test (712 pts)\n",
      "Saved File 5: Train (719 pts), Test (720 pts)\n",
      "Saved File 6: Train (719 pts), Test (720 pts)\n",
      "Saved File 8: Train (710 pts), Test (710 pts)\n",
      "Saved File 9: Train (730 pts), Test (731 pts)\n",
      "Saved File 10: Train (719 pts), Test (720 pts)\n",
      "Saved File 11: Train (719 pts), Test (720 pts)\n",
      "Saved File 12: Train (719 pts), Test (720 pts)\n",
      "Saved File 13: Train (719 pts), Test (720 pts)\n",
      "Saved File 14: Train (719 pts), Test (720 pts)\n",
      "Saved File 15: Train (719 pts), Test (720 pts)\n",
      "Saved File 16: Train (730 pts), Test (731 pts)\n",
      "Saved File 17: Train (712 pts), Test (712 pts)\n",
      "Saved File 18: Train (730 pts), Test (731 pts)\n",
      "Saved File 19: Train (712 pts), Test (712 pts)\n",
      "Saved File 20: Train (711 pts), Test (711 pts)\n",
      "Saved File 21: Train (710 pts), Test (710 pts)\n",
      "Saved File 22: Train (710 pts), Test (710 pts)\n",
      "Saved File 23: Train (710 pts), Test (710 pts)\n",
      "Saved File 24: Train (730 pts), Test (731 pts)\n",
      "Saved File 25: Train (717 pts), Test (718 pts)\n",
      "Saved File 26: Train (717 pts), Test (718 pts)\n",
      "Saved File 27: Train (713 pts), Test (714 pts)\n",
      "Saved File 28: Train (720 pts), Test (721 pts)\n",
      "Saved File 29: Train (720 pts), Test (721 pts)\n",
      "Saved File 30: Train (730 pts), Test (731 pts)\n",
      "Saved File 31: Train (713 pts), Test (714 pts)\n",
      "Saved File 32: Train (713 pts), Test (714 pts)\n",
      "Saved File 33: Train (719 pts), Test (720 pts)\n",
      "Saved File 34: Train (713 pts), Test (714 pts)\n",
      "Saved File 35: Train (713 pts), Test (714 pts)\n",
      "Saved File 36: Train (730 pts), Test (731 pts)\n",
      "Saved File 37: Train (717 pts), Test (717 pts)\n",
      "Saved File 38: Train (713 pts), Test (714 pts)\n",
      "Saved File 39: Train (713 pts), Test (714 pts)\n",
      "Saved File 40: Train (713 pts), Test (714 pts)\n",
      "Saved File 41: Train (717 pts), Test (718 pts)\n",
      "Saved File 42: Train (720 pts), Test (720 pts)\n",
      "Saved File 43: Train (720 pts), Test (720 pts)\n",
      "Saved File 44: Train (730 pts), Test (731 pts)\n",
      "Saved File 45: Train (720 pts), Test (720 pts)\n",
      "Saved File 46: Train (720 pts), Test (721 pts)\n",
      "Saved File 47: Train (713 pts), Test (714 pts)\n",
      "Saved File 48: Train (719 pts), Test (720 pts)\n",
      "Saved File 49: Train (730 pts), Test (731 pts)\n",
      "Saved File 50: Train (719 pts), Test (720 pts)\n",
      "Saved File 51: Train (713 pts), Test (714 pts)\n",
      "Saved File 52: Train (716 pts), Test (716 pts)\n",
      "Saved File 53: Train (730 pts), Test (731 pts)\n",
      "Saved File 54: Train (370 pts), Test (371 pts)\n",
      "Saved File 55: Train (713 pts), Test (714 pts)\n",
      "Saved File 56: Train (713 pts), Test (714 pts)\n",
      "Saved File 57: Train (720 pts), Test (721 pts)\n",
      "Saved File 58: Train (717 pts), Test (718 pts)\n",
      "Saved File 59: Train (711 pts), Test (712 pts)\n",
      "Saved File 60: Train (730 pts), Test (731 pts)\n",
      "Saved File 61: Train (720 pts), Test (721 pts)\n",
      "Saved File 62: Train (370 pts), Test (371 pts)\n",
      "Saved File 63: Train (719 pts), Test (720 pts)\n",
      "Saved File 64: Train (720 pts), Test (721 pts)\n",
      "Saved File 65: Train (712 pts), Test (712 pts)\n",
      "Saved File 66: Train (712 pts), Test (712 pts)\n",
      "Saved File 67: Train (711 pts), Test (712 pts)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "c2089247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T01:48:09.263560613Z",
     "start_time": "2025-11-19T01:48:09.186920631Z"
    }
   },
   "source": [
    "stats = []\n",
    "\n",
    "for id in ids:\n",
    "    file_path = os.path.join(data_dir, f\"{id}.csv\")\n",
    "    df = pl.read_csv(\n",
    "        file_path,\n",
    "        schema={\"timestamp\": pl.UInt64, \"value\": pl.Float64, \"label\": pl.Int8},\n",
    "    )\n",
    "\n",
    "    cutoff = df[\"timestamp\"][int(len(df) * split_at) - 1]\n",
    "    total_points = len(df)\n",
    "    total_anomalies = (df[\"label\"] == 1).sum()\n",
    "\n",
    "    train_df = df.filter(pl.col(\"timestamp\") <= cutoff)\n",
    "    train_points = len(train_df)\n",
    "    train_anomalies = (train_df[\"label\"] == 1).sum()\n",
    "\n",
    "    test_df = df.filter(pl.col(\"timestamp\") > cutoff)\n",
    "    test_points = len(test_df)\n",
    "    test_anomalies = (test_df[\"label\"] == 1).sum()\n",
    "\n",
    "    stats.append(\n",
    "        {\n",
    "            \"ID\": id,\n",
    "            \"Total Points\": total_points,\n",
    "            \"Total Anomalies\": total_anomalies,\n",
    "            \"Anomaly Rate (%)\": total_anomalies / total_points * 100,\n",
    "            \"Train Points\": train_points,\n",
    "            \"Train Anomalies\": train_anomalies,\n",
    "            \"Train Anomaly Rate (%)\": train_anomalies / train_points * 100,\n",
    "            \"Test Points\": test_points,\n",
    "            \"Test Anomalies\": test_anomalies,\n",
    "            \"Test Anomaly Rate (%)\": test_anomalies / test_points * 100,\n",
    "        }\n",
    "    )\n",
    "\n",
    "stats_df = pl.DataFrame(stats)\n",
    "print(\"Yahoo Time Series Statistics Summary\")\n",
    "stats_df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo Time Series Statistics Summary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (66, 10)\n",
       "┌─────┬────────┬───────────┬──────────────┬───┬────────────────────┬────────┬───────────┬──────────┐\n",
       "│ ID  ┆ Total  ┆ Total     ┆ Anomaly Rate ┆ … ┆ Train Anomaly Rate ┆ Test   ┆ Test      ┆ Test     │\n",
       "│ --- ┆ Points ┆ Anomalies ┆ (%)          ┆   ┆ (%)                ┆ Points ┆ Anomalies ┆ Anomaly  │\n",
       "│ i64 ┆ ---    ┆ ---       ┆ ---          ┆   ┆ ---                ┆ ---    ┆ ---       ┆ Rate (%) │\n",
       "│     ┆ i64    ┆ i64       ┆ f64          ┆   ┆ f64                ┆ i64    ┆ i64       ┆ ---      │\n",
       "│     ┆        ┆           ┆              ┆   ┆                    ┆        ┆           ┆ f64      │\n",
       "╞═════╪════════╪═══════════╪══════════════╪═══╪════════════════════╪════════╪═══════════╪══════════╡\n",
       "│ 1   ┆ 1420   ┆ 2         ┆ 0.140845     ┆ … ┆ 0.0                ┆ 710    ┆ 2         ┆ 0.28169  │\n",
       "│ 2   ┆ 1439   ┆ 12        ┆ 0.833912     ┆ … ┆ 0.0                ┆ 720    ┆ 12        ┆ 1.666667 │\n",
       "│ 3   ┆ 1461   ┆ 14        ┆ 0.958248     ┆ … ┆ 0.0                ┆ 731    ┆ 14        ┆ 1.915185 │\n",
       "│ 4   ┆ 1423   ┆ 10        ┆ 0.702741     ┆ … ┆ 0.140647           ┆ 712    ┆ 9         ┆ 1.264045 │\n",
       "│ 5   ┆ 1439   ┆ 2         ┆ 0.138985     ┆ … ┆ 0.278164           ┆ 720    ┆ 0         ┆ 0.0      │\n",
       "│ …   ┆ …      ┆ …         ┆ …            ┆ … ┆ …                  ┆ …      ┆ …         ┆ …        │\n",
       "│ 63  ┆ 1439   ┆ 8         ┆ 0.555942     ┆ … ┆ 0.0                ┆ 720    ┆ 8         ┆ 1.111111 │\n",
       "│ 64  ┆ 1441   ┆ 0         ┆ 0.0          ┆ … ┆ 0.0                ┆ 721    ┆ 0         ┆ 0.0      │\n",
       "│ 65  ┆ 1424   ┆ 17        ┆ 1.19382      ┆ … ┆ 0.0                ┆ 712    ┆ 17        ┆ 2.38764  │\n",
       "│ 66  ┆ 1424   ┆ 21        ┆ 1.474719     ┆ … ┆ 0.0                ┆ 712    ┆ 21        ┆ 2.949438 │\n",
       "│ 67  ┆ 1423   ┆ 23        ┆ 1.616304     ┆ … ┆ 0.0                ┆ 712    ┆ 23        ┆ 3.230337 │\n",
       "└─────┴────────┴───────────┴──────────────┴───┴────────────────────┴────────┴───────────┴──────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (66, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID</th><th>Total Points</th><th>Total Anomalies</th><th>Anomaly Rate (%)</th><th>Train Points</th><th>Train Anomalies</th><th>Train Anomaly Rate (%)</th><th>Test Points</th><th>Test Anomalies</th><th>Test Anomaly Rate (%)</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>1420</td><td>2</td><td>0.140845</td><td>710</td><td>0</td><td>0.0</td><td>710</td><td>2</td><td>0.28169</td></tr><tr><td>2</td><td>1439</td><td>12</td><td>0.833912</td><td>719</td><td>0</td><td>0.0</td><td>720</td><td>12</td><td>1.666667</td></tr><tr><td>3</td><td>1461</td><td>14</td><td>0.958248</td><td>730</td><td>0</td><td>0.0</td><td>731</td><td>14</td><td>1.915185</td></tr><tr><td>4</td><td>1423</td><td>10</td><td>0.702741</td><td>711</td><td>1</td><td>0.140647</td><td>712</td><td>9</td><td>1.264045</td></tr><tr><td>5</td><td>1439</td><td>2</td><td>0.138985</td><td>719</td><td>2</td><td>0.278164</td><td>720</td><td>0</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>63</td><td>1439</td><td>8</td><td>0.555942</td><td>719</td><td>0</td><td>0.0</td><td>720</td><td>8</td><td>1.111111</td></tr><tr><td>64</td><td>1441</td><td>0</td><td>0.0</td><td>720</td><td>0</td><td>0.0</td><td>721</td><td>0</td><td>0.0</td></tr><tr><td>65</td><td>1424</td><td>17</td><td>1.19382</td><td>712</td><td>0</td><td>0.0</td><td>712</td><td>17</td><td>2.38764</td></tr><tr><td>66</td><td>1424</td><td>21</td><td>1.474719</td><td>712</td><td>0</td><td>0.0</td><td>712</td><td>21</td><td>2.949438</td></tr><tr><td>67</td><td>1423</td><td>23</td><td>1.616304</td><td>711</td><td>0</td><td>0.0</td><td>712</td><td>23</td><td>3.230337</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectrum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
