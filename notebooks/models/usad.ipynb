{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etniX_KTlJ5U"
   },
   "source": [
    "# USAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6u1DGKsAlLF-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Ensure USAD and device are imported\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from spectrum.models import USAD\n",
    "from spectrum.utils import device\n",
    "from spectrum.utils.random import set_random_state\n",
    "from spectrum.models import USAD\n",
    "from spectrum.utils import device\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.edgecolor\": \"0.3\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"font.size\": 12,\n",
    "        \"axes.titlesize\": 14,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"axes.titleweight\": \"bold\",\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"legend.frameon\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "set_random_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yi9S0SGnDKNc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 3 datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 1\n",
      "  training model...\n",
      "Epoch [0], val_loss1: 0.2475, val_loss2: 0.2502\n",
      "Epoch [1], val_loss1: 0.2444, val_loss2: 0.0000\n",
      "Epoch [2], val_loss1: 0.2406, val_loss2: -0.0810\n",
      "Epoch [3], val_loss1: 0.2365, val_loss2: -0.1197\n",
      "Epoch [4], val_loss1: 0.2321, val_loss2: -0.1414\n",
      "Epoch [5], val_loss1: 0.2273, val_loss2: -0.1545\n",
      "Epoch [6], val_loss1: 0.2222, val_loss2: -0.1625\n",
      "Epoch [7], val_loss1: 0.2167, val_loss2: -0.1671\n",
      "Epoch [8], val_loss1: 0.2105, val_loss2: -0.1691\n",
      "Epoch [9], val_loss1: 0.2038, val_loss2: -0.1692\n",
      "Epoch [10], val_loss1: 0.1963, val_loss2: -0.1673\n",
      "Epoch [11], val_loss1: 0.1876, val_loss2: -0.1633\n",
      "Epoch [12], val_loss1: 0.1783, val_loss2: -0.1580\n",
      "Epoch [13], val_loss1: 0.1684, val_loss2: -0.1515\n",
      "Epoch [14], val_loss1: 0.1581, val_loss2: -0.1439\n",
      "Epoch [15], val_loss1: 0.1468, val_loss2: -0.1350\n",
      "Epoch [16], val_loss1: 0.1348, val_loss2: -0.1250\n",
      "Epoch [17], val_loss1: 0.1226, val_loss2: -0.1144\n",
      "Epoch [18], val_loss1: 0.1100, val_loss2: -0.1032\n",
      "Epoch [19], val_loss1: 0.0976, val_loss2: -0.0921\n",
      "Epoch [20], val_loss1: 0.0856, val_loss2: -0.0810\n",
      "Epoch [21], val_loss1: 0.0739, val_loss2: -0.0702\n",
      "Epoch [22], val_loss1: 0.0630, val_loss2: -0.0601\n",
      "Epoch [23], val_loss1: 0.0531, val_loss2: -0.0507\n",
      "Epoch [24], val_loss1: 0.0442, val_loss2: -0.0423\n",
      "Epoch [25], val_loss1: 0.0364, val_loss2: -0.0349\n",
      "Epoch [26], val_loss1: 0.0298, val_loss2: -0.0287\n",
      "Epoch [27], val_loss1: 0.0244, val_loss2: -0.0234\n",
      "Epoch [28], val_loss1: 0.0199, val_loss2: -0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:  33%|███▎      | 1/3 [00:05<00:10,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], val_loss1: 0.0162, val_loss2: -0.0156\n",
      "  anomaly detection...\n",
      "  Scores stats: min=0.010234, max=907494.750000, mean=2772.411377\n",
      "  finding best threshold...\n",
      "  results saved to: ../../results/models/usad/1.csv\n",
      "  ID 1 completed:\n",
      "    best_threshold: 0.0102\n",
      "    f1: 1.0000\n",
      "    precision: 1.0000\n",
      "    recall: 1.0000\n",
      "    accuracy: 1.0000\n",
      "processing: 2\n",
      "  training model...\n",
      "Epoch [0], val_loss1: 0.2372, val_loss2: 0.2424\n",
      "Epoch [1], val_loss1: 0.2314, val_loss2: 0.0001\n",
      "Epoch [2], val_loss1: 0.2240, val_loss2: -0.0762\n",
      "Epoch [3], val_loss1: 0.2152, val_loss2: -0.1100\n",
      "Epoch [4], val_loss1: 0.2051, val_loss2: -0.1260\n",
      "Epoch [5], val_loss1: 0.1938, val_loss2: -0.1325\n",
      "Epoch [6], val_loss1: 0.1812, val_loss2: -0.1328\n",
      "Epoch [7], val_loss1: 0.1664, val_loss2: -0.1281\n",
      "Epoch [8], val_loss1: 0.1498, val_loss2: -0.1194\n",
      "Epoch [9], val_loss1: 0.1324, val_loss2: -0.1084\n",
      "Epoch [10], val_loss1: 0.1151, val_loss2: -0.0962\n",
      "Epoch [11], val_loss1: 0.0986, val_loss2: -0.0838\n",
      "Epoch [12], val_loss1: 0.0832, val_loss2: -0.0717\n",
      "Epoch [13], val_loss1: 0.0693, val_loss2: -0.0603\n",
      "Epoch [14], val_loss1: 0.0570, val_loss2: -0.0501\n",
      "Epoch [15], val_loss1: 0.0464, val_loss2: -0.0411\n",
      "Epoch [16], val_loss1: 0.0375, val_loss2: -0.0334\n",
      "Epoch [17], val_loss1: 0.0301, val_loss2: -0.0270\n",
      "Epoch [18], val_loss1: 0.0241, val_loss2: -0.0217\n",
      "Epoch [19], val_loss1: 0.0192, val_loss2: -0.0173\n",
      "Epoch [20], val_loss1: 0.0152, val_loss2: -0.0138\n",
      "Epoch [21], val_loss1: 0.0119, val_loss2: -0.0108\n",
      "Epoch [22], val_loss1: 0.0093, val_loss2: -0.0085\n",
      "Epoch [23], val_loss1: 0.0073, val_loss2: -0.0066\n",
      "Epoch [24], val_loss1: 0.0057, val_loss2: -0.0052\n",
      "Epoch [25], val_loss1: 0.0045, val_loss2: -0.0041\n",
      "Epoch [26], val_loss1: 0.0036, val_loss2: -0.0033\n",
      "Epoch [27], val_loss1: 0.0029, val_loss2: -0.0027\n",
      "Epoch [28], val_loss1: 0.0024, val_loss2: -0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:  67%|██████▋   | 2/3 [00:11<00:05,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], val_loss1: 0.0021, val_loss2: -0.0019\n",
      "  anomaly detection...\n",
      "  Scores stats: min=0.002832, max=0.908030, mean=0.005790\n",
      "  finding best threshold...\n",
      "  results saved to: ../../results/models/usad/2.csv\n",
      "  ID 2 completed:\n",
      "    best_threshold: 0.0028\n",
      "    f1: 1.0000\n",
      "    precision: 1.0000\n",
      "    recall: 1.0000\n",
      "    accuracy: 1.0000\n",
      "processing: 3\n",
      "  training model...\n",
      "Epoch [0], val_loss1: 0.2419, val_loss2: 0.2486\n",
      "Epoch [1], val_loss1: 0.2404, val_loss2: 0.0000\n",
      "Epoch [2], val_loss1: 0.2363, val_loss2: -0.0802\n",
      "Epoch [3], val_loss1: 0.2310, val_loss2: -0.1178\n",
      "Epoch [4], val_loss1: 0.2243, val_loss2: -0.1375\n",
      "Epoch [5], val_loss1: 0.2158, val_loss2: -0.1473\n",
      "Epoch [6], val_loss1: 0.2057, val_loss2: -0.1507\n",
      "Epoch [7], val_loss1: 0.1940, val_loss2: -0.1495\n",
      "Epoch [8], val_loss1: 0.1806, val_loss2: -0.1445\n",
      "Epoch [9], val_loss1: 0.1659, val_loss2: -0.1367\n",
      "Epoch [10], val_loss1: 0.1501, val_loss2: -0.1266\n",
      "Epoch [11], val_loss1: 0.1335, val_loss2: -0.1148\n",
      "Epoch [12], val_loss1: 0.1165, val_loss2: -0.1018\n",
      "Epoch [13], val_loss1: 0.0996, val_loss2: -0.0882\n",
      "Epoch [14], val_loss1: 0.0832, val_loss2: -0.0746\n",
      "Epoch [15], val_loss1: 0.0679, val_loss2: -0.0615\n",
      "Epoch [16], val_loss1: 0.0540, val_loss2: -0.0494\n",
      "Epoch [17], val_loss1: 0.0421, val_loss2: -0.0389\n",
      "Epoch [18], val_loss1: 0.0323, val_loss2: -0.0300\n",
      "Epoch [19], val_loss1: 0.0245, val_loss2: -0.0229\n",
      "Epoch [20], val_loss1: 0.0185, val_loss2: -0.0174\n",
      "Epoch [21], val_loss1: 0.0141, val_loss2: -0.0133\n",
      "Epoch [22], val_loss1: 0.0109, val_loss2: -0.0103\n",
      "Epoch [23], val_loss1: 0.0086, val_loss2: -0.0081\n",
      "Epoch [24], val_loss1: 0.0070, val_loss2: -0.0066\n",
      "Epoch [25], val_loss1: 0.0058, val_loss2: -0.0055\n",
      "Epoch [26], val_loss1: 0.0050, val_loss2: -0.0047\n",
      "Epoch [27], val_loss1: 0.0043, val_loss2: -0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 3/3 [00:15<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], val_loss1: 0.0039, val_loss2: -0.0036\n",
      "Epoch [29], val_loss1: 0.0035, val_loss2: -0.0033\n",
      "  anomaly detection...\n",
      "  Scores stats: min=0.005141, max=0.908112, mean=0.008081\n",
      "  finding best threshold...\n",
      "  results saved to: ../../results/models/usad/3.csv\n",
      "  ID 3 completed:\n",
      "    best_threshold: 0.9078\n",
      "    f1: 0.0000\n",
      "    precision: 0.0000\n",
      "    recall: 0.0000\n",
      "    accuracy: 0.9998\n",
      "summary results saved to: ../../results/models/usad/usad.csv\n",
      "\n",
      "================================================================================\n",
      "USAD anomaly detection results\n",
      "================================================================================\n",
      "processed 3 datasets\n",
      "average F1: 0.6667 ± 0.5774\n",
      "average precision: 0.6667 ± 0.5774\n",
      "average recall: 0.6667 ± 0.5774\n",
      "average accuracy: 0.9999 ± 0.0001\n",
      "average training time: 5.03s\n",
      "average scoring time: 0.03s\n",
      "================================================================================\n",
      "details:\n",
      "   id   f1  precision  recall  accuracy  best_threshold  tp  fp    tn  fn\n",
      "0   1  1.0        1.0     1.0    1.0000          0.0102  66   0  4243   0\n",
      "1   2  1.0        1.0     1.0    1.0000          0.0028  66   0  4243   0\n",
      "2   3  0.0        0.0     0.0    0.9998          0.9078   0   1  4308   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "N_EPOCHS = 30\n",
    "HIDDEN_SIZE = 100\n",
    "WINDOW_SIZE = 12\n",
    "\n",
    "results_dir = \"../../results/models/usad\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "selected_ids = [1, 2, 3]\n",
    "\n",
    "def find_best_threshold(scores, true_labels, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        # Handle case where scores are all same (e.g. 0)\n",
    "        if np.min(scores) == np.max(scores):\n",
    "            thresholds = [scores[0]]\n",
    "        else:\n",
    "            thresholds = [np.percentile(scores, p) for p in range(0, 90, 5)]\n",
    "            thresholds.extend([np.percentile(scores, p) for p in range(90, 100, 1)])\n",
    "            thresholds.extend([np.percentile(scores, p) for p in [99.1, 99.3, 99.5, 99.7, 99.9, 99.95, 99.99]])\n",
    "            \n",
    "    thresholds = sorted(list(set(thresholds)), reverse=True)\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_threshold = thresholds[0] if len(thresholds) > 0 else 0.0\n",
    "    \n",
    "    best_metrics = {\n",
    "        'threshold': best_threshold,\n",
    "        'accuracy': 0.0,\n",
    "        'precision': 0.0,\n",
    "        'recall': 0.0,\n",
    "        'f1': 0.0,\n",
    "        'fnr': 0.0,\n",
    "        'fpr': 0.0,\n",
    "        'tp': 0,\n",
    "        'fp': 0,\n",
    "        'tn': 0,\n",
    "        'fn': 0\n",
    "    }\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        pred_labels = (scores > threshold).astype(int)\n",
    "        TP = ((true_labels == 1) & (pred_labels == 1)).sum()\n",
    "        FP = ((true_labels == 0) & (pred_labels == 1)).sum()\n",
    "        TN = ((true_labels == 0) & (pred_labels == 0)).sum()\n",
    "        FN = ((true_labels == 1) & (pred_labels == 0)).sum()\n",
    "\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        fnr = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "        fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_metrics = {\n",
    "                'threshold': threshold,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'fnr': fnr,\n",
    "                'fpr': fpr,\n",
    "                'tp': TP,\n",
    "                'fp': FP,\n",
    "                'tn': TN,\n",
    "                'fn': FN\n",
    "            }\n",
    "            \n",
    "    return best_threshold, best_metrics\n",
    "\n",
    "def process_single_id(data_id):\n",
    "    print(f\"processing: {data_id}\")\n",
    "    \n",
    "    # Read data\n",
    "    train_df_raw = pd.read_csv(f\"../../datasets/Tencent/train/{data_id}.csv\")\n",
    "    test_df_raw = pd.read_csv(f\"../../datasets/Tencent/test/{data_id}.csv\")\n",
    "    \n",
    "    # Prepare Train Data\n",
    "    train_vals = train_df_raw.drop([\"timestamp\", \"label\"], axis=1, errors='ignore')\n",
    "    train_vals = train_vals.astype(float)\n",
    "    \n",
    "    # Prepare Test Data\n",
    "    test_vals = test_df_raw.drop([\"timestamp\", \"label\"], axis=1, errors='ignore')\n",
    "    test_vals = test_vals.astype(float)\n",
    "    \n",
    "    # Normalization\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_train = min_max_scaler.fit_transform(train_vals.values)\n",
    "    x_test = min_max_scaler.transform(test_vals.values)\n",
    "    \n",
    "    # Create Windows\n",
    "    def make_windows(data_arr):\n",
    "        # data_arr: (N, F)\n",
    "        n = data_arr.shape[0]\n",
    "        if n <= WINDOW_SIZE:\n",
    "            return np.empty((0, WINDOW_SIZE, data_arr.shape[1]))\n",
    "        indexer = np.arange(WINDOW_SIZE)[None, :] + np.arange(n - WINDOW_SIZE + 1)[:, None]\n",
    "        return data_arr[indexer]\n",
    "\n",
    "    train_windows = make_windows(x_train)\n",
    "    test_windows = make_windows(x_test)\n",
    "    \n",
    "    # Flatten windows for USAD\n",
    "    w_size = WINDOW_SIZE * x_train.shape[1]\n",
    "    z_size = WINDOW_SIZE * HIDDEN_SIZE\n",
    "    \n",
    "    train_windows_flat = train_windows.reshape(-1, w_size)\n",
    "    test_windows_flat = test_windows.reshape(-1, w_size)\n",
    "    \n",
    "    # Split Train/Val\n",
    "    split_idx = int(0.8 * len(train_windows_flat))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        data_utils.TensorDataset(\n",
    "            torch.from_numpy(train_windows_flat[:split_idx]).float()\n",
    "        ),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        data_utils.TensorDataset(\n",
    "            torch.from_numpy(train_windows_flat[split_idx:]).float()\n",
    "        ),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        data_utils.TensorDataset(\n",
    "            torch.from_numpy(test_windows_flat).float()\n",
    "        ),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model = USAD(N_EPOCHS, w_size, z_size).to(device())\n",
    "    \n",
    "    print(\"  training model...\")\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_loader, val_loader)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(\"  anomaly detection...\")\n",
    "    start_time = time.time()\n",
    "    results_list = model.predict(test_loader)\n",
    "    if len(results_list) > 0:\n",
    "        scores = torch.cat(results_list).cpu().numpy()\n",
    "    else:\n",
    "        scores = np.array([])\n",
    "    scoring_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  Scores stats: min={scores.min():.6f}, max={scores.max():.6f}, mean={scores.mean():.6f}\")\n",
    "    \n",
    "    # Window-based Labeling Logic\n",
    "    test_true_labels = test_df_raw[\"label\"].to_numpy()\n",
    "    \n",
    "    # Create windows of labels using the same make_windows function\n",
    "    # We reshape labels to (N, 1) then flatten the result to (num_windows, WINDOW_SIZE)\n",
    "    label_windows = make_windows(test_true_labels.reshape(-1, 1)).reshape(-1, WINDOW_SIZE)\n",
    "    \n",
    "    # If ANY point in window is anomaly (1), then window label is 1\n",
    "    y_test = (label_windows.sum(axis=1) > 0).astype(int)\n",
    "    \n",
    "    # Align lengths\n",
    "    min_len = min(len(scores), len(y_test))\n",
    "    scores = scores[:min_len]\n",
    "    y_test = y_test[:min_len]\n",
    "\n",
    "    print(\"  finding best threshold...\")\n",
    "    best_threshold, best_metrics = find_best_threshold(scores, y_test)\n",
    "    \n",
    "    # Save Results (Complete Data)\n",
    "    full_df = pd.concat([train_df_raw, test_df_raw])\n",
    "    \n",
    "    if \"value\" in full_df.columns:\n",
    "        complete_values = full_df[\"value\"].to_numpy()\n",
    "    else:\n",
    "        complete_values = full_df.iloc[:, 1].to_numpy() # Use first feature column\n",
    "        \n",
    "    if \"label\" in full_df.columns:\n",
    "        complete_labels = full_df[\"label\"].to_numpy()\n",
    "    else:\n",
    "        complete_labels = np.zeros(len(complete_values))\n",
    "        \n",
    "    if \"timestamp\" in full_df.columns:\n",
    "        complete_timestamps = full_df[\"timestamp\"].to_numpy()\n",
    "    else:\n",
    "        complete_timestamps = range(len(complete_values))\n",
    "        \n",
    "    complete_predictions = np.zeros(len(complete_values))\n",
    "    complete_anomaly_scores = np.zeros(len(complete_values))\n",
    "    \n",
    "    # Align predictions\n",
    "    # Test scores correspond to windows. \n",
    "    # We align the score to the END of the window (point-based alignment for visualization)\n",
    "    # Start index in full_df: len(train) + WINDOW_SIZE - 1\n",
    "    \n",
    "    pred_start_idx = len(train_df_raw) + WINDOW_SIZE - 1\n",
    "    \n",
    "    end_idx = pred_start_idx + len(scores)\n",
    "    if end_idx > len(complete_values):\n",
    "        end_idx = len(complete_values)\n",
    "        scores = scores[:end_idx - pred_start_idx]\n",
    "        \n",
    "    complete_predictions[pred_start_idx:end_idx] = (scores > best_threshold).astype(int)\n",
    "    complete_anomaly_scores[pred_start_idx:end_idx] = scores\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'timestamp': complete_timestamps,\n",
    "        'value': complete_values,\n",
    "        'label': complete_labels,\n",
    "        'predicted': complete_predictions,\n",
    "        'anomaly_score': complete_anomaly_scores\n",
    "    })\n",
    "    \n",
    "    output_file = os.path.join(results_dir, f\"{data_id}.csv\")\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"  results saved to: {output_file}\")\n",
    "    \n",
    "    return {\n",
    "        'id': data_id,\n",
    "        'training_time': training_time,\n",
    "        'testing_time': scoring_time,\n",
    "        'total_time': training_time + scoring_time,\n",
    "        'train_samples': len(train_df_raw),\n",
    "        'test_samples': len(test_df_raw),\n",
    "        'best_threshold': best_threshold,\n",
    "        **best_metrics\n",
    "    }\n",
    "\n",
    "# Main Loop\n",
    "all_results = []\n",
    "print(f\"processing {len(selected_ids)} datasets...\")\n",
    "\n",
    "for data_id in tqdm(selected_ids, desc=\"processing\"):\n",
    "    try:\n",
    "        result = process_single_id(data_id)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        print(f\"  ID {data_id} completed:\")\n",
    "        print(f\"    best_threshold: {result['best_threshold']:.4f}\")\n",
    "        print(f\"    f1: {result['f1']:.4f}\")\n",
    "        print(f\"    precision: {result['precision']:.4f}\")\n",
    "        print(f\"    recall: {result['recall']:.4f}\")\n",
    "        print(f\"    accuracy: {result['accuracy']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  processing {data_id} failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    summary_df = pd.DataFrame(all_results)\n",
    "    summary_file = os.path.join(results_dir, \"usad.csv\")\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"summary results saved to: {summary_file}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"USAD anomaly detection results\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"processed {len(all_results)} datasets\")\n",
    "    print(f\"average F1: {summary_df['f1'].mean():.4f} ± {summary_df['f1'].std():.4f}\")\n",
    "    print(f\"average precision: {summary_df['precision'].mean():.4f} ± {summary_df['precision'].std():.4f}\")\n",
    "    print(f\"average recall: {summary_df['recall'].mean():.4f} ± {summary_df['recall'].std():.4f}\")\n",
    "    print(f\"average accuracy: {summary_df['accuracy'].mean():.4f} ± {summary_df['accuracy'].std():.4f}\")\n",
    "    print(f\"average training time: {summary_df['training_time'].mean():.2f}s\")\n",
    "    print(f\"average scoring time: {summary_df['testing_time'].mean():.2f}s\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"details:\")\n",
    "    display_cols = ['id', 'f1', 'precision', 'recall', 'accuracy', 'best_threshold', 'tp', 'fp', 'tn', 'fn']\n",
    "    print(summary_df[display_cols].round(4))\n",
    "else:\n",
    "    print(\"no results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Processing Synthetic Dataset (USAD)...\n",
      "========================================\n",
      "  Train shape: (2500, 12)\n",
      "  Test shape: (2500, 12)\n",
      "  training model...\n",
      "Epoch [0], val_loss1: 0.0414, val_loss2: 0.0413\n",
      "Epoch [1], val_loss1: 0.0417, val_loss2: -0.0000\n",
      "Epoch [2], val_loss1: 0.0421, val_loss2: -0.0140\n",
      "Epoch [3], val_loss1: 0.0425, val_loss2: -0.0212\n",
      "Epoch [4], val_loss1: 0.0429, val_loss2: -0.0257\n",
      "Epoch [5], val_loss1: 0.0434, val_loss2: -0.0288\n",
      "Epoch [6], val_loss1: 0.0440, val_loss2: -0.0312\n",
      "Epoch [7], val_loss1: 0.0446, val_loss2: -0.0332\n",
      "Epoch [8], val_loss1: 0.0453, val_loss2: -0.0349\n",
      "Epoch [9], val_loss1: 0.0461, val_loss2: -0.0365\n",
      "Epoch [10], val_loss1: 0.0470, val_loss2: -0.0381\n",
      "Epoch [11], val_loss1: 0.0483, val_loss2: -0.0399\n",
      "Epoch [12], val_loss1: 0.0500, val_loss2: -0.0420\n",
      "Epoch [13], val_loss1: 0.0521, val_loss2: -0.0444\n",
      "Epoch [14], val_loss1: 0.0533, val_loss2: -0.0460\n",
      "Epoch [15], val_loss1: 0.0531, val_loss2: -0.0463\n",
      "Epoch [16], val_loss1: 0.0521, val_loss2: -0.0457\n",
      "Epoch [17], val_loss1: 0.0508, val_loss2: -0.0449\n",
      "Epoch [18], val_loss1: 0.0496, val_loss2: -0.0442\n",
      "Epoch [19], val_loss1: 0.0488, val_loss2: -0.0437\n",
      "Epoch [20], val_loss1: 0.0482, val_loss2: -0.0435\n",
      "Epoch [21], val_loss1: 0.0479, val_loss2: -0.0434\n",
      "Epoch [22], val_loss1: 0.0477, val_loss2: -0.0435\n",
      "Epoch [23], val_loss1: 0.0477, val_loss2: -0.0436\n",
      "Epoch [24], val_loss1: 0.0478, val_loss2: -0.0438\n",
      "Epoch [25], val_loss1: 0.0479, val_loss2: -0.0441\n",
      "Epoch [26], val_loss1: 0.0480, val_loss2: -0.0443\n",
      "Epoch [27], val_loss1: 0.0480, val_loss2: -0.0444\n",
      "Epoch [28], val_loss1: 0.0480, val_loss2: -0.0446\n",
      "Epoch [29], val_loss1: 0.0480, val_loss2: -0.0447\n",
      "  anomaly detection...\n",
      "  Scores stats: min=0.047080, max=0.274899, mean=0.114472\n",
      "  finding best threshold...\n",
      "  results saved to: ../../results/models/usad_synthetic/synthetic.csv\n",
      "\n",
      "Results:\n",
      "  best_threshold: 0.1103\n",
      "  threshold: 0.11025878041982651\n",
      "  accuracy: 0.5922\n",
      "  precision: 0.3930\n",
      "  recall: 0.7452\n",
      "  f1: 0.5146\n",
      "  fnr: 0.2548\n",
      "  fpr: 0.4703\n",
      "  tp: 538\n",
      "  fp: 831\n",
      "  tn: 936\n",
      "  fn: 184\n"
     ]
    }
   ],
   "source": [
    "def process_synthetic_data_usad():\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"Processing Synthetic Dataset (USAD)...\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Paths\n",
    "    train_path = \"../../datasets/synthetic/train/train.csv\"\n",
    "    test_path = \"../../datasets/synthetic/test/test.csv\"\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        print(f\"Error: {train_path} not found. Please run preprocess/synthetic.ipynb first.\")\n",
    "        return\n",
    "\n",
    "    # Read data\n",
    "    train_df_raw = pd.read_csv(train_path)\n",
    "    test_df_raw = pd.read_csv(test_path)\n",
    "    \n",
    "    print(f\"  Train shape: {train_df_raw.shape}\")\n",
    "    print(f\"  Test shape: {test_df_raw.shape}\")\n",
    "    \n",
    "    # Prepare Numeric Data\n",
    "    # Drop timestamp and label\n",
    "    cols_to_drop = [\"timestamp\", \"label\"]\n",
    "    train_vals = train_df_raw.drop([c for c in cols_to_drop if c in train_df_raw.columns], axis=1)\n",
    "    test_vals = test_df_raw.drop([c for c in cols_to_drop if c in test_df_raw.columns], axis=1)\n",
    "    \n",
    "    train_vals = train_vals.astype(float)\n",
    "    test_vals = test_vals.astype(float)\n",
    "    \n",
    "    # Normalization\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_train = min_max_scaler.fit_transform(train_vals.values)\n",
    "    x_test = min_max_scaler.transform(test_vals.values)\n",
    "    \n",
    "    # Windowing\n",
    "    def make_windows(data_arr):\n",
    "        n = data_arr.shape[0]\n",
    "        if n <= WINDOW_SIZE:\n",
    "            return np.empty((0, WINDOW_SIZE, data_arr.shape[1]))\n",
    "        indexer = np.arange(WINDOW_SIZE)[None, :] + np.arange(n - WINDOW_SIZE + 1)[:, None]\n",
    "        return data_arr[indexer]\n",
    "\n",
    "    train_windows = make_windows(x_train)\n",
    "    test_windows = make_windows(x_test)\n",
    "    \n",
    "    # Flatten for USAD\n",
    "    w_size = WINDOW_SIZE * x_train.shape[1]\n",
    "    z_size = WINDOW_SIZE * HIDDEN_SIZE\n",
    "    \n",
    "    train_windows_flat = train_windows.reshape(-1, w_size)\n",
    "    test_windows_flat = test_windows.reshape(-1, w_size)\n",
    "    \n",
    "    # DataLoaders\n",
    "    split_idx = int(0.8 * len(train_windows_flat))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        data_utils.TensorDataset(torch.from_numpy(train_windows_flat[:split_idx]).float()),\n",
    "        batch_size=BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        data_utils.TensorDataset(torch.from_numpy(train_windows_flat[split_idx:]).float()),\n",
    "        batch_size=BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        data_utils.TensorDataset(torch.from_numpy(test_windows_flat).float()),\n",
    "        batch_size=BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model = USAD(N_EPOCHS, w_size, z_size).to(device())\n",
    "    \n",
    "    print(\"  training model...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(train_loader, val_loader)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(\"  anomaly detection...\")\n",
    "    start_time = time.time()\n",
    "    results_list = model.predict(test_loader)\n",
    "    if len(results_list) > 0:\n",
    "        scores = torch.cat(results_list).cpu().numpy()\n",
    "    else:\n",
    "        scores = np.array([])\n",
    "    scoring_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  Scores stats: min={scores.min():.6f}, max={scores.max():.6f}, mean={scores.mean():.6f}\")\n",
    "    \n",
    "    # Window-based Labeling Logic\n",
    "    if \"label\" in test_df_raw.columns:\n",
    "        test_true_labels = test_df_raw[\"label\"].to_numpy()\n",
    "        label_windows = make_windows(test_true_labels.reshape(-1, 1)).reshape(-1, WINDOW_SIZE)\n",
    "        y_test = (label_windows.sum(axis=1) > 0).astype(int)\n",
    "    else:\n",
    "        y_test = np.zeros(len(scores))\n",
    "\n",
    "    # Align lengths\n",
    "    min_len = min(len(scores), len(y_test))\n",
    "    scores = scores[:min_len]\n",
    "    y_test = y_test[:min_len]\n",
    "\n",
    "    print(\"  finding best threshold...\")\n",
    "    best_threshold, best_metrics = find_best_threshold(scores, y_test)\n",
    "    \n",
    "    # Save Results\n",
    "    results_dir_syn = \"../../results/models/usad_synthetic\"\n",
    "    os.makedirs(results_dir_syn, exist_ok=True)\n",
    "    \n",
    "    full_df = pd.concat([train_df_raw, test_df_raw])\n",
    "    \n",
    "    # Use first feature column for visualization\n",
    "    feature_cols = [c for c in train_df_raw.columns if c not in cols_to_drop]\n",
    "    if feature_cols:\n",
    "        complete_values = full_df[feature_cols[0]].to_numpy()\n",
    "    else:\n",
    "        complete_values = full_df.iloc[:, 0].to_numpy()\n",
    "\n",
    "    if \"label\" in full_df.columns:\n",
    "        complete_labels = full_df[\"label\"].to_numpy()\n",
    "    else:\n",
    "        complete_labels = np.zeros(len(complete_values))\n",
    "        \n",
    "    if \"timestamp\" in full_df.columns:\n",
    "        complete_timestamps = full_df[\"timestamp\"].to_numpy()\n",
    "    else:\n",
    "        complete_timestamps = range(len(complete_values))\n",
    "        \n",
    "    complete_predictions = np.zeros(len(complete_values))\n",
    "    complete_anomaly_scores = np.zeros(len(complete_values))\n",
    "    \n",
    "    # Align predictions\n",
    "    pred_start_idx = len(train_df_raw) + WINDOW_SIZE - 1\n",
    "    \n",
    "    end_idx = pred_start_idx + len(scores)\n",
    "    if end_idx > len(complete_values):\n",
    "        end_idx = len(complete_values)\n",
    "        scores = scores[:end_idx - pred_start_idx]\n",
    "        \n",
    "    complete_predictions[pred_start_idx:end_idx] = (scores > best_threshold).astype(int)\n",
    "    complete_anomaly_scores[pred_start_idx:end_idx] = scores\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'timestamp': complete_timestamps,\n",
    "        'value': complete_values,\n",
    "        'label': complete_labels,\n",
    "        'predicted': complete_predictions,\n",
    "        'anomaly_score': complete_anomaly_scores\n",
    "    })\n",
    "    \n",
    "    output_file = os.path.join(results_dir_syn, \"synthetic.csv\")\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"  results saved to: {output_file}\")\n",
    "    \n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"  best_threshold: {best_threshold:.4f}\")\n",
    "    for k, v in best_metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {k}: {v}\")\n",
    "\n",
    "# Run\n",
    "process_synthetic_data_usad()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "USAD_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "spectrum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
