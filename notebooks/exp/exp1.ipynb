{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df449216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Ensure USAD and device are imported\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from spectrum.models import USAD\n",
    "from spectrum.utils import device\n",
    "from spectrum.utils.random import set_random_state\n",
    "from spectrum.models import USAD, SpectralResidual\n",
    "from spectrum.utils import device\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.edgecolor\": \"0.3\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"font.size\": 12,\n",
    "        \"axes.titlesize\": 14,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"axes.titleweight\": \"bold\",\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"figure.dpi\": 120,\n",
    "        \"legend.frameon\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "set_random_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c3fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 1 (Hybrid SR + USAD)\n",
      "  Running SR on system_usage:0...\n",
      "  Running USAD on 4 features...\n",
      "Epoch [0], val_loss1: 0.2184, val_loss2: 0.2194\n",
      "Epoch [1], val_loss1: 0.1966, val_loss2: -0.0021\n",
      "Epoch [2], val_loss1: 0.1633, val_loss2: -0.0588\n",
      "Epoch [3], val_loss1: 0.1265, val_loss2: -0.0681\n",
      "Epoch [4], val_loss1: 0.0931, val_loss2: -0.0590\n",
      "Epoch [5], val_loss1: 0.0685, val_loss2: -0.0468\n",
      "Epoch [6], val_loss1: 0.0531, val_loss2: -0.0376\n",
      "Epoch [7], val_loss1: 0.0446, val_loss2: -0.0325\n",
      "Epoch [8], val_loss1: 0.0410, val_loss2: -0.0314\n",
      "Epoch [9], val_loss1: 0.0415, val_loss2: -0.0336\n",
      "Epoch [10], val_loss1: 0.0445, val_loss2: -0.0375\n",
      "Epoch [11], val_loss1: 0.0450, val_loss2: -0.0387\n",
      "Epoch [12], val_loss1: 0.0411, val_loss2: -0.0358\n",
      "Epoch [13], val_loss1: 0.0371, val_loss2: -0.0326\n",
      "Epoch [14], val_loss1: 0.0371, val_loss2: -0.0328\n",
      "Epoch [15], val_loss1: 0.0394, val_loss2: -0.0350\n",
      "Epoch [16], val_loss1: 0.0413, val_loss2: -0.0370\n",
      "Epoch [17], val_loss1: 0.0417, val_loss2: -0.0376\n",
      "Epoch [18], val_loss1: 0.0407, val_loss2: -0.0370\n",
      "Epoch [19], val_loss1: 0.0396, val_loss2: -0.0362\n",
      "  Aligned lengths: 4289\n",
      "  Optimizing SR threshold...\n",
      "    SR F1: 0.7143\n",
      "  Optimizing USAD threshold...\n",
      "    USAD F1: 0.1263\n",
      "  Hybrid Result: F1=0.1649, P=0.0909, R=0.8889\n",
      "  Saved to ../../results/models/sr_usad/1.csv\n",
      "\n",
      "Processing: 2 (Hybrid SR + USAD)\n",
      "  Running SR on system_usage:0...\n",
      "  Running USAD on 4 features...\n",
      "Epoch [0], val_loss1: 0.2199, val_loss2: 0.2248\n",
      "Epoch [1], val_loss1: 0.2125, val_loss2: -0.0002\n",
      "Epoch [2], val_loss1: 0.1998, val_loss2: -0.0704\n",
      "Epoch [3], val_loss1: 0.1826, val_loss2: -0.0988\n",
      "Epoch [4], val_loss1: 0.1623, val_loss2: -0.1079\n",
      "Epoch [5], val_loss1: 0.1402, val_loss2: -0.1044\n",
      "Epoch [6], val_loss1: 0.1193, val_loss2: -0.0940\n",
      "Epoch [7], val_loss1: 0.1020, val_loss2: -0.0822\n",
      "Epoch [8], val_loss1: 0.0868, val_loss2: -0.0700\n",
      "Epoch [9], val_loss1: 0.0740, val_loss2: -0.0591\n",
      "Epoch [10], val_loss1: 0.0639, val_loss2: -0.0506\n",
      "Epoch [11], val_loss1: 0.0563, val_loss2: -0.0445\n",
      "Epoch [12], val_loss1: 0.0507, val_loss2: -0.0404\n",
      "Epoch [13], val_loss1: 0.0467, val_loss2: -0.0377\n",
      "Epoch [14], val_loss1: 0.0440, val_loss2: -0.0362\n",
      "Epoch [15], val_loss1: 0.0421, val_loss2: -0.0353\n",
      "Epoch [16], val_loss1: 0.0410, val_loss2: -0.0350\n",
      "Epoch [17], val_loss1: 0.0403, val_loss2: -0.0349\n",
      "Epoch [18], val_loss1: 0.0402, val_loss2: -0.0353\n",
      "Epoch [19], val_loss1: 0.0407, val_loss2: -0.0362\n",
      "  Aligned lengths: 4289\n",
      "  Optimizing SR threshold...\n",
      "    SR F1: 0.7143\n",
      "  Optimizing USAD threshold...\n",
      "    USAD F1: 0.0500\n",
      "  Hybrid Result: F1=0.2667, P=0.1667, R=0.6667\n",
      "  Saved to ../../results/models/sr_usad/2.csv\n",
      "\n",
      "Processing: 3 (Hybrid SR + USAD)\n",
      "  Running SR on system_usage:0...\n",
      "  Running USAD on 4 features...\n",
      "Epoch [0], val_loss1: 0.2200, val_loss2: 0.2210\n",
      "Epoch [1], val_loss1: 0.2046, val_loss2: -0.0003\n",
      "Epoch [2], val_loss1: 0.1804, val_loss2: -0.0624\n",
      "Epoch [3], val_loss1: 0.1502, val_loss2: -0.0787\n",
      "Epoch [4], val_loss1: 0.1192, val_loss2: -0.0749\n",
      "Epoch [5], val_loss1: 0.0931, val_loss2: -0.0645\n",
      "Epoch [6], val_loss1: 0.0738, val_loss2: -0.0542\n",
      "Epoch [7], val_loss1: 0.0609, val_loss2: -0.0465\n",
      "Epoch [8], val_loss1: 0.0530, val_loss2: -0.0418\n",
      "Epoch [9], val_loss1: 0.0488, val_loss2: -0.0396\n",
      "Epoch [10], val_loss1: 0.0480, val_loss2: -0.0399\n",
      "Epoch [11], val_loss1: 0.0467, val_loss2: -0.0398\n",
      "Epoch [12], val_loss1: 0.0420, val_loss2: -0.0363\n",
      "Epoch [13], val_loss1: 0.0366, val_loss2: -0.0319\n",
      "Epoch [14], val_loss1: 0.0356, val_loss2: -0.0315\n",
      "Epoch [15], val_loss1: 0.0396, val_loss2: -0.0355\n",
      "Epoch [16], val_loss1: 0.0428, val_loss2: -0.0387\n",
      "Epoch [17], val_loss1: 0.0418, val_loss2: -0.0380\n",
      "Epoch [18], val_loss1: 0.0394, val_loss2: -0.0360\n",
      "Epoch [19], val_loss1: 0.0386, val_loss2: -0.0354\n",
      "  Aligned lengths: 4289\n",
      "  Optimizing SR threshold...\n",
      "    SR F1: 0.0000\n",
      "  Optimizing USAD threshold...\n",
      "    USAD F1: 0.0000\n",
      "  Hybrid Result: F1=0.0000, P=0.0000, R=0.0000\n",
      "  Saved to ../../results/models/sr_usad/3.csv\n",
      "\n",
      "Summary:\n",
      "   id      f1  precision  recall  accuracy   sr_f1  usad_f1\n",
      "0   1  0.1649     0.0909  0.8889    0.9811  0.7143   0.1263\n",
      "1   2  0.2667     0.1667  0.6667    0.9923  0.7143   0.0500\n",
      "2   3  0.0000     0.0000  0.0000    0.9995  0.0000   0.0000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "N_EPOCHS = 20\n",
    "HIDDEN_SIZE = 100\n",
    "WINDOW_SIZE = 32\n",
    "\n",
    "results_dir = \"../../results/models/sr_usad\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "selected_ids = [1, 2, 3]\n",
    "\n",
    "def find_best_threshold(scores, true_labels, thresholds=None):\n",
    "    if np.isnan(scores).any() or np.isinf(scores).any():\n",
    "        scores = np.nan_to_num(scores, nan=0.0, posinf=np.max(scores[np.isfinite(scores)]) if np.any(np.isfinite(scores)) else 1.0)\n",
    "\n",
    "    if thresholds is None:\n",
    "        if np.min(scores) == np.max(scores):\n",
    "            thresholds = [scores[0]]\n",
    "        else:\n",
    "            thresholds = [np.percentile(scores, p) for p in range(0, 90, 5)]\n",
    "            thresholds.extend([np.percentile(scores, p) for p in range(90, 100, 1)])\n",
    "            thresholds.extend([np.percentile(scores, p) for p in [99.1, 99.3, 99.5, 99.7, 99.9, 99.95, 99.99]])\n",
    "            \n",
    "    thresholds = sorted(list(set(thresholds)), reverse=True)\n",
    "    best_f1 = -1\n",
    "    best_threshold = thresholds[0] if len(thresholds) > 0 else 0.0\n",
    "    best_metrics = {}\n",
    "\n",
    "    true_labels = true_labels.astype(int)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        pred_labels = (scores > threshold).astype(int)\n",
    "        TP = ((true_labels == 1) & (pred_labels == 1)).sum()\n",
    "        FP = ((true_labels == 0) & (pred_labels == 1)).sum()\n",
    "        TN = ((true_labels == 0) & (pred_labels == 0)).sum()\n",
    "        FN = ((true_labels == 1) & (pred_labels == 0)).sum()\n",
    "\n",
    "        accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_metrics = {'threshold': threshold, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "            \n",
    "    return best_threshold, best_metrics\n",
    "\n",
    "def process_hybrid(data_id):\n",
    "    print(f\"\\nProcessing: {data_id} (Hybrid SR + USAD)\")\n",
    "    \n",
    "    # Read data\n",
    "    train_df = pd.read_csv(f\"../../datasets/Tencent/train/{data_id}.csv\")\n",
    "    test_df = pd.read_csv(f\"../../datasets/Tencent/test/{data_id}.csv\")\n",
    "    \n",
    "    # Labels\n",
    "    test_labels = test_df[\"label\"].to_numpy().astype(int)\n",
    "    \n",
    "    # --- 1. SR on system_usage:0 ---\n",
    "    sr_col = \"system_usage:0\"\n",
    "    sr_scores = np.zeros(len(test_df))\n",
    "    \n",
    "    if sr_col in test_df.columns:\n",
    "        print(f\"  Running SR on {sr_col}...\")\n",
    "        sr_model = SpectralResidual(window_size=WINDOW_SIZE)\n",
    "        # Input: pl.Series\n",
    "        sr_scores_pl = sr_model.predict(pl.Series(test_df[sr_col].values))\n",
    "        sr_scores = sr_scores_pl\n",
    "        sr_scores = np.nan_to_num(sr_scores, nan=0.0)\n",
    "    else:\n",
    "        print(f\"  Warning: {sr_col} missing. SR scores set to 0.\")\n",
    "\n",
    "    # --- 2. USAD on Rest ---\n",
    "    cols_exclude = [\"timestamp\", \"label\", sr_col]\n",
    "    train_usad = train_df.drop([c for c in cols_exclude if c in train_df.columns], axis=1).astype(float)\n",
    "    test_usad = test_df.drop([c for c in cols_exclude if c in test_df.columns], axis=1).astype(float)\n",
    "    \n",
    "    print(f\"  Running USAD on {train_usad.shape[1]} features...\")\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(train_usad.values)\n",
    "    x_test = scaler.transform(test_usad.values)\n",
    "    \n",
    "    # Windowing\n",
    "    def make_windows(data, ws):\n",
    "        n = data.shape[0]\n",
    "        if n <= ws: return np.empty((0, ws, data.shape[1]))\n",
    "        idx = np.arange(ws)[None, :] + np.arange(n - ws + 1)[:, None]\n",
    "        return data[idx]\n",
    "\n",
    "    train_win = make_windows(x_train, WINDOW_SIZE)\n",
    "    test_win = make_windows(x_test, WINDOW_SIZE)\n",
    "    \n",
    "    # Flatten\n",
    "    w_size = WINDOW_SIZE * x_train.shape[1]\n",
    "    z_size = WINDOW_SIZE * HIDDEN_SIZE\n",
    "    train_flat = train_win.reshape(-1, w_size)\n",
    "    test_flat = test_win.reshape(-1, w_size)\n",
    "    \n",
    "    # DataLoaders\n",
    "    split = int(0.8 * len(train_flat))\n",
    "    train_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(torch.from_numpy(train_flat[:split]).float()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(torch.from_numpy(train_flat[split:]).float()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(torch.from_numpy(test_flat).float()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Train USAD\n",
    "    model_usad = USAD(N_EPOCHS, w_size, z_size).to(device())\n",
    "    model_usad.fit(train_loader, val_loader)\n",
    "    \n",
    "    # Predict USAD\n",
    "    res = model_usad.predict(test_loader)\n",
    "    if len(res) > 0:\n",
    "        usad_scores = torch.cat(res).cpu().numpy()\n",
    "    else:\n",
    "        usad_scores = np.array([])\n",
    "        \n",
    "    # --- 3. Combine ---\n",
    "    valid_len = len(usad_scores)\n",
    "    start_idx = WINDOW_SIZE - 1\n",
    "    \n",
    "    sr_scores_aligned = sr_scores[start_idx : start_idx + valid_len]\n",
    "    labels_aligned = test_labels[start_idx : start_idx + valid_len]\n",
    "    \n",
    "    print(f\"  Aligned lengths: {valid_len}\")\n",
    "    \n",
    "    # Optimize Thresholds\n",
    "    print(\"  Optimizing SR threshold...\")\n",
    "    best_th_sr, metrics_sr = find_best_threshold(sr_scores_aligned, labels_aligned)\n",
    "    pred_sr = (sr_scores_aligned > best_th_sr).astype(int)\n",
    "    print(f\"    SR F1: {metrics_sr.get('f1', 0):.4f}\")\n",
    "    \n",
    "    print(\"  Optimizing USAD threshold...\")\n",
    "    best_th_usad, metrics_usad = find_best_threshold(usad_scores, labels_aligned)\n",
    "    pred_usad = (usad_scores > best_th_usad).astype(int)\n",
    "    print(f\"    USAD F1: {metrics_usad.get('f1', 0):.4f}\")\n",
    "    \n",
    "    # Logical OR\n",
    "    pred_final = (pred_sr | pred_usad).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    TP = ((labels_aligned == 1) & (pred_final == 1)).sum()\n",
    "    FP = ((labels_aligned == 0) & (pred_final == 1)).sum()\n",
    "    TN = ((labels_aligned == 0) & (pred_final == 0)).sum()\n",
    "    FN = ((labels_aligned == 1) & (pred_final == 0)).sum()\n",
    "    \n",
    "    accuracy = (TP + TN) / len(labels_aligned) if len(labels_aligned) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"  Hybrid Result: F1={f1:.4f}, P={precision:.4f}, R={recall:.4f}\")\n",
    "    \n",
    "    # Save Results\n",
    "    # Construct DataFrame aligned with original Test DF\n",
    "    # We fill 'predicted' column. 0 for untrained part?\n",
    "    complete_predictions = np.zeros(len(test_df))\n",
    "    complete_predictions[start_idx : start_idx + valid_len] = pred_final\n",
    "    \n",
    "    # We can save timestamp, value, label, predicted\n",
    "    res_df = test_df.copy()\n",
    "    res_df[\"predicted\"] = complete_predictions\n",
    "    res_df[\"sr_score\"] = sr_scores\n",
    "    \n",
    "    # usad_score aligned\n",
    "    usad_scores_full = np.zeros(len(test_df))\n",
    "    usad_scores_full[start_idx : start_idx + valid_len] = usad_scores\n",
    "    res_df[\"usad_score\"] = usad_scores_full\n",
    "    \n",
    "    output_file = os.path.join(results_dir, f\"{data_id}.csv\")\n",
    "    res_df.to_csv(output_file, index=False)\n",
    "    print(f\"  Saved to {output_file}\")\n",
    "    \n",
    "    return {\n",
    "        'id': data_id,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'sr_f1': metrics_sr.get('f1', 0),\n",
    "        'usad_f1': metrics_usad.get('f1', 0)\n",
    "    }\n",
    "\n",
    "# Run Loop\n",
    "results = []\n",
    "for i in selected_ids:\n",
    "    results.append(process_hybrid(i))\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary:\")\n",
    "print(summary_df.round(4))\n",
    "summary_df.to_csv(os.path.join(results_dir, \"summary.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec94f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 1 (Hybrid SR + LSTM)\n",
      "  Running SR on system_usage:0...\n",
      "  Running LSTM on 4 features...\n",
      "  Aligned lengths: 4288\n",
      "  Optimizing SR threshold...\n",
      "    SR F1: 0.7143\n",
      "  Optimizing LSTM threshold...\n",
      "    LSTM F1: 0.7143\n",
      "  Hybrid Result: F1=1.0000, P=1.0000, R=1.0000\n",
      "  Saved to ../../results/models/sr_lstm/1.csv\n",
      "\n",
      "Processing: 2 (Hybrid SR + LSTM)\n",
      "  Running SR on system_usage:0...\n",
      "  Running LSTM on 4 features...\n",
      "  Aligned lengths: 4288\n",
      "  Optimizing SR threshold...\n",
      "    SR F1: 0.7143\n",
      "  Optimizing LSTM threshold...\n",
      "    LSTM F1: 0.7143\n",
      "  Hybrid Result: F1=1.0000, P=1.0000, R=1.0000\n",
      "  Saved to ../../results/models/sr_lstm/2.csv\n",
      "\n",
      "Processing: 3 (Hybrid SR + LSTM)\n",
      "  Running SR on system_usage:0...\n",
      "  Running LSTM on 4 features...\n",
      "  Aligned lengths: 4288\n",
      "  Optimizing SR threshold...\n",
      "    SR F1: 0.0000\n",
      "  Optimizing LSTM threshold...\n",
      "    LSTM F1: 0.0000\n",
      "  Hybrid Result: F1=0.0000, P=0.0000, R=0.0000\n",
      "  Saved to ../../results/models/sr_lstm/3.csv\n",
      "\n",
      "LSTM Hybrid Summary:\n",
      "   id   f1  precision  recall  accuracy   sr_f1  lstm_f1\n",
      "0   1  1.0        1.0     1.0    1.0000  0.7143   0.7143\n",
      "1   2  1.0        1.0     1.0    1.0000  0.7143   0.7143\n",
      "2   3  0.0        0.0     0.0    0.9995  0.0000   0.0000\n"
     ]
    }
   ],
   "source": [
    "from spectrum.models import LSTM\n",
    "\n",
    "results_dir_lstm = \"../../results/models/sr_lstm\"\n",
    "os.makedirs(results_dir_lstm, exist_ok=True)\n",
    "\n",
    "def process_hybrid_lstm(data_id):\n",
    "    print(f\"\\nProcessing: {data_id} (Hybrid SR + LSTM)\")\n",
    "    \n",
    "    # Read data\n",
    "    train_df = pd.read_csv(f\"../../datasets/Tencent/train/{data_id}.csv\")\n",
    "    test_df = pd.read_csv(f\"../../datasets/Tencent/test/{data_id}.csv\")\n",
    "    \n",
    "    test_labels = test_df[\"label\"].to_numpy().astype(int)\n",
    "    \n",
    "    # --- 1. SR ---\n",
    "    sr_col = \"system_usage:0\"\n",
    "    sr_scores = np.zeros(len(test_df))\n",
    "    if sr_col in test_df.columns:\n",
    "        print(f\"  Running SR on {sr_col}...\")\n",
    "        sr_model = SpectralResidual(window_size=WINDOW_SIZE)\n",
    "        sr_scores = sr_model.predict(pl.Series(test_df[sr_col].values))\n",
    "        sr_scores = np.nan_to_num(sr_scores, nan=0.0)\n",
    "    else:\n",
    "        print(f\"  Warning: {sr_col} missing.\")\n",
    "\n",
    "    # --- 2. LSTM ---\n",
    "    cols_exclude = [\"timestamp\", \"label\", sr_col]\n",
    "    train_lstm = train_df.drop([c for c in cols_exclude if c in train_df.columns], axis=1)\n",
    "    test_lstm = test_df.drop([c for c in cols_exclude if c in test_df.columns], axis=1)\n",
    "    \n",
    "    print(f\"  Running LSTM on {train_lstm.shape[1]} features...\")\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(train_lstm.values)\n",
    "    x_test = scaler.transform(test_lstm.values)\n",
    "    \n",
    "    input_size = x_train.shape[1]\n",
    "    output_dims = list(range(input_size))\n",
    "    \n",
    "    # Increase epochs if needed, using N_EPOCHS from cell 1\n",
    "    model_lstm = LSTM(input_size=input_size, output_dims=output_dims, epochs=N_EPOCHS, window_size=WINDOW_SIZE)\n",
    "    model_lstm.fit(x_train)\n",
    "    \n",
    "    lstm_scores = model_lstm.predict(x_test)\n",
    "    \n",
    "    # --- 3. Combine ---\n",
    "    valid_len = len(lstm_scores)\n",
    "    # LSTM predictions usually align to end\n",
    "    start_idx = len(test_df) - valid_len\n",
    "    \n",
    "    sr_scores_aligned = sr_scores[start_idx : start_idx + valid_len]\n",
    "    labels_aligned = test_labels[start_idx : start_idx + valid_len]\n",
    "    \n",
    "    print(f\"  Aligned lengths: {valid_len}\")\n",
    "    \n",
    "    print(\"  Optimizing SR threshold...\")\n",
    "    best_th_sr, metrics_sr = find_best_threshold(sr_scores_aligned, labels_aligned)\n",
    "    pred_sr = (sr_scores_aligned > best_th_sr).astype(int)\n",
    "    print(f\"    SR F1: {metrics_sr.get('f1', 0):.4f}\")\n",
    "    \n",
    "    print(\"  Optimizing LSTM threshold...\")\n",
    "    best_th_lstm, metrics_lstm = find_best_threshold(lstm_scores, labels_aligned)\n",
    "    pred_lstm = (lstm_scores > best_th_lstm).astype(int)\n",
    "    print(f\"    LSTM F1: {metrics_lstm.get('f1', 0):.4f}\")\n",
    "    \n",
    "    pred_final = (pred_sr | pred_lstm).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    TP = ((labels_aligned == 1) & (pred_final == 1)).sum()\n",
    "    FP = ((labels_aligned == 0) & (pred_final == 1)).sum()\n",
    "    TN = ((labels_aligned == 0) & (pred_final == 0)).sum()\n",
    "    FN = ((labels_aligned == 1) & (pred_final == 0)).sum()\n",
    "    \n",
    "    accuracy = (TP + TN) / len(labels_aligned) if len(labels_aligned) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"  Hybrid Result: F1={f1:.4f}, P={precision:.4f}, R={recall:.4f}\")\n",
    "    \n",
    "    # Save\n",
    "    res_df = test_df.copy()\n",
    "    complete_predictions = np.zeros(len(test_df))\n",
    "    complete_predictions[start_idx : start_idx + valid_len] = pred_final\n",
    "    res_df[\"predicted\"] = complete_predictions\n",
    "    res_df[\"sr_score\"] = sr_scores\n",
    "    \n",
    "    lstm_scores_full = np.zeros(len(test_df))\n",
    "    lstm_scores_full[start_idx : start_idx + valid_len] = lstm_scores\n",
    "    res_df[\"lstm_score\"] = lstm_scores_full\n",
    "    \n",
    "    res_df.to_csv(os.path.join(results_dir_lstm, f\"{data_id}.csv\"), index=False)\n",
    "    print(f\"  Saved to {results_dir_lstm}/{data_id}.csv\")\n",
    "    \n",
    "    return {\n",
    "        'id': data_id,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'sr_f1': metrics_sr.get('f1', 0),\n",
    "        'lstm_f1': metrics_lstm.get('f1', 0)\n",
    "    }\n",
    "\n",
    "results_lstm = []\n",
    "for i in selected_ids:\n",
    "    results_lstm.append(process_hybrid_lstm(i))\n",
    "\n",
    "print(\"\\nLSTM Hybrid Summary:\")\n",
    "print(pd.DataFrame(results_lstm).round(4))\n",
    "pd.DataFrame(results_lstm).to_csv(os.path.join(results_dir_lstm, \"summary.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectrum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
